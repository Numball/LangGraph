# LangGraph - Minimal Workflow Engine

A FastAPI-based rule-based workflow engine that executes directed acyclic graphs (DAGs) with support for conditional branching and looping. No machine learning modelsâ€”pure Python logic.

![Status](https://img.shields.io/badge/status-beta-brightgreen)
![Python](https://img.shields.io/badge/python-3.7+-blue)
![License](https://img.shields.io/badge/license-MIT-green)

## Features

âœ¨ **Core Engine Capabilities:**
- **Pure Python Nodes**: Define workflow steps as simple Python functions that read/modify shared state
- **State Management**: State passed as dictionaries between nodes for clean data flow
- **Edge Mapping**: Explicit control flow via source â†’ target node definitions
- **Conditional Branching**: Route execution based on state values using condition functions
- **Loop Support**: Execute nodes repeatedly until conditions are met (with max iteration protection)
- **Tool Registry**: Built-in dictionary-based function registry for shared tools across workflows
- **No ML Models**: Purely rule-based executionâ€”no TensorFlow, PyTorch, or similar dependencies

âœ… **FastAPI Endpoints:**
- `POST /graph/create`: Create and register a new workflow graph
- `POST /graph/run`: Execute a graph with initial state; get final state + execution log
- `GET /graph/state/{run_id}`: Retrieve execution history and current state
- `GET /docs`: Interactive Swagger UI for testing

ðŸ“Š **Workflow Examples:**
- **Code Review** (default): Extract code, check syntax, analyze style, generate report
- **Data Summarization**: (Optional - can be implemented)
- **Data Quality Check**: (Optional - can be implemented)

## Quick Start

### 1. Installation

Clone and setup:
```bash
git clone <repo-url>
cd LangGraph
pip install -r requirements.txt
```

**Requirements:**
- Python 3.7+
- FastAPI 0.100+
- Uvicorn 0.24+
- Pydantic 2.0+

### 2. Run Tests

**Test 1: Core Workflow Engine**
```bash
py test_workflow.py
```
Output: Executes a complete code review workflow and shows execution log.

**Test 2: API Endpoints**
```bash
py test_api.py
```
Output: Tests all three endpoints with sample graph and state queries.

### 3. Start the Server

```bash
py run_server.py
```

Server runs on `http://localhost:8000`
- API docs (interactive): `http://localhost:8000/docs`
- ReDoc (alternative): `http://localhost:8000/redoc`

### 4. Example API Calls

**Create a Graph:**
```bash
curl -X POST "http://localhost:8000/graph/create" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "SimpleWorkflow",
    "nodes": [
      {"name": "node_a", "type": "task"},
      {"name": "node_b", "type": "task"}
    ],
    "edges": [
      {"source": "node_a", "target": "node_b"}
    ]
  }'
```

**Run a Graph:**
```bash
curl -X POST "http://localhost:8000/graph/run" \
  -H "Content-Type: application/json" \
  -d '{
    "graph_id": "YOUR_GRAPH_ID",
    "initial_state": {"input_value": 42},
    "max_iterations": 100
  }'
```

**Get Execution State:**
```bash
curl "http://localhost:8000/graph/state/YOUR_RUN_ID"
```

## Project Structure

```
/app
â”œâ”€â”€ __init__.py              # Package init
â”œâ”€â”€ main.py                  # FastAPI application + endpoints
â”œâ”€â”€ engine.py                # Core Graph/Node/Edge logic
â”œâ”€â”€ schemas.py               # Pydantic models for validation
â”œâ”€â”€ tools.py                 # Tool registry (helper functions)
â””â”€â”€ /workflows
    â”œâ”€â”€ __init__.py
    â””â”€â”€ code_review.py       # Sample workflow (Option A)

/
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ test_workflow.py         # Workflow engine unit tests
â”œâ”€â”€ test_api.py              # API endpoint tests  
â”œâ”€â”€ run_server.py            # Development server runner
â””â”€â”€ README.md                # This file
```

## How It Works

### 1. Define a Graph

```python
from app.engine import WorkflowEngine

engine = WorkflowEngine()
graph = engine.create_graph("MyWorkflow")

# Add nodes (pure Python functions)
def my_task(state):
    state["result"] = state.get("input", 0) * 2
    return state

graph.add_node("double_value", my_task)
graph.add_node("process", another_func)

# Add edges (define execution flow)
graph.add_edge("double_value", "process")

# Optional: Add conditions for branching
def should_continue(state):
    return state.get("result", 0) > 10

graph.add_edge("process", "finalize", condition=should_continue)
```

### 2. Execute the Graph

```python
initial_state = {"input": 5}
run_id, final_state, execution_log = engine.run_graph(
    graph.id,
    initial_state,
    max_iterations=100
)

# Access results
print(final_state)  # {'input': 5, 'result': 10, ...}
print(execution_log)  # List of ExecutionEntry objects
```

### 3. Use the Tool Registry

```python
from app.tools import tool_registry

# Register a tool
@tool_registry.register("uppercase")
def make_uppercase(text):
    return text.upper()

# Use in a node
def format_node(state):
    state["formatted"] = tool_registry.call("uppercase", state["text"])
    return state
```

## Core Components

### `engine.py` - Workflow Engine

**Node**: Pure Python function + metadata
```python
Node(name: str, func: Callable, node_type: str = "task")
```

**Edge**: Connection between nodes with optional condition
```python
Edge(source: str, target: str, condition: Optional[Callable] = None)
```

**Graph**: DAG container with execution logic
```python
Graph.execute(initial_state, start_nodes, max_iterations) 
  â†’ (final_state, execution_log)
```

**WorkflowEngine**: High-level manager for multiple graphs
```python
engine.create_graph(name) â†’ Graph
engine.run_graph(graph_id, state, max_iterations) â†’ (run_id, state, log)
engine.get_run_state(run_id) â†’ (state, log)
```

### `schemas.py` - Pydantic Models

Type-safe request/response models for API validation:
- `CreateGraphRequest`: Define a graph
- `RunGraphRequest`: Execute a graph
- `GetStateResponse`: Query execution results
- `ExecutionLog`: Detailed node execution records

### `tools.py` - Tool Registry

Dictionary-based function registry for reusable helper functions:
```python
@tool_registry.register("my_tool")
def my_function(arg1, arg2):
    return result

# Call from nodes
result = tool_registry.call("my_tool", x, y)
```

Includes example tools:
- `extract_text`: Limit text length
- `count_words`: Word counting
- `analyze_sentiment`: Rule-based sentiment (no ML)
- `format_output`: JSON/string formatting

## Testing

### Unit Tests

`test_workflow.py`: Tests the core engine
- Graph creation and execution
- Node execution with state passing
- Edge routing
- Execution logging

```bash
py test_workflow.py
```

### API Tests

`test_api.py`: Tests FastAPI endpoints
- POST /graph/create
- POST /graph/run
- GET /graph/state/{run_id}
- Error handling (404, 400)

```bash
py test_api.py
```

All tests verify:
- âœ“ Correct status codes
- âœ“ Response schema validation
- âœ“ State passing between nodes
- âœ“ Execution logging accuracy

## Future Improvements

With more time, consider implementing:

### 1. **Database Persistence**
   - Replace in-memory `run_history` with SQLite/PostgreSQL
   - Store graphs and run results for long-term auditing
   - Query execution history: `GET /runs?graph_id=X&status=error`

### 2. **Parallel Execution**
   - Execute independent nodes concurrently (async/await improvements)
   - Reduce execution time for DAGs with parallelizable paths
   - Use `asyncio.gather()` for independent node execution

### 3. **Advanced Branching**
   - Switch/case-style routing (multiple conditions)
   - Join nodes (merge multiple branches)
   - Default/fallback edges if no conditions match

### 4. **Workflow Visualization**
   - `/graph/visualize/{graph_id}` endpoint returning SVG/Mermaid diagram
   - Interactive graph editor UI
   - Visual debugging of execution flows

### 5. **Debugging & Monitoring**
   - Real-time execution tracing (WebSocket updates)
   - Breakpoints and step-through execution
   - Performance profiling per node
   - Error recovery strategies (retry logic)

### 6. **Dynamic Node Registration**
   - Register nodes at runtime without code changes
   - Hot-reload workflow definitions
   - YAML/JSON workflow DSL parser

### 7. **Deployment**
   - Docker containerization (Dockerfile)
   - Kubernetes manifests
   - CI/CD pipeline setup
   - Multi-worker Uvicorn configuration

### 8. **Additional Sample Workflows**
   - **Data Summarization**: Extract â†’ Tokenize â†’ Summarize â†’ Format
   - **Data Quality Checks**: Validate â†’ Profile â†’ Report
   - **Document Processing**: Parse â†’ Extract â†’ Enrich â†’ Store
   - **Form Validation**: Validate input â†’ Check rules â†’ Notify

### 9. **Security Enhancements**
   - Authentication & authorization (JWT tokens)
   - Rate limiting per user/API key
   - Input validation & sanitization
   - Audit logging of all operations

### 10. **Configuration Management**
   - Environment-based configs (.env files)
   - Feature flags for A/B testing
   - Workflow versioning and rollback
   - Tool/node whitelisting

## Implementation Notes

### Design Decisions

1. **Pure Python Functions**: Nodes are simple callables for clarity and testability
2. **Dictionary-based State**: Flexible, human-readable state passing (vs. Pydantic models everywhere)
3. **In-Memory Storage**: No DB complexity for MVP; easy to upgrade later
4. **No ML Libraries**: Focuses on rule-based logic; demonstrates software architecture skills
5. **Type Hints**: Pydantic models + type annotations for clean code

### Why No Machine Learning?

The assignment explicitly asks to avoid ML models. The focus is on demonstrating:
- Clean Python code structure
- Correct async/await patterns (where applicable)
- Type safety with Pydantic
- API design best practices
- Workflow orchestration logic

## Evaluation Checklist

âœ… **Phase 1: Core Functionality**
- [x] Pure Python nodes reading/modifying shared state
- [x] State passed as dictionary between nodes
- [x] Edges define execution order with mapping mechanism
- [x] Conditional branching (if/else logic based on state)
- [x] Loop support with iteration limits
- [x] Tool registry (dictionary of helper functions)
- [x] Sample workflow implemented (Code Review)
- [x] Rule-based (no ML models)

âœ… **Phase 2: API & Interface**
- [x] POST /graph/create: Accepts JSON, returns graph_id
- [x] POST /graph/run: Accepts graph_id + state, returns final_state + log
- [x] GET /graph/state/{run_id}: Returns current state
- [x] Persistence: In-memory (upgradable to DB)

âœ… **Phase 3: Environment & Packaging**
- [x] requirements.txt with all dependencies
- [x] Clean folder structure (/app separate from root)
- [x] Engine logic separated from FastAPI
- [ ] Docker support (optional)

âœ… **Phase 4: Documentation**
- [x] How to Run: Installation & server startup
- [x] Features: List of engine capabilities
- [x] Example Requests: curl commands & code samples
- [x] Future Improvements: Detailed enhancement ideas

âœ… **Phase 5: Code Hygiene**
- [x] Type hints throughout (Pydantic models)
- [x] Clean Python code
- [x] No ML dependencies
- [x] Proper error handling

## License

MIT - See LICENSE file for details

## Contact

For questions or issues, please open an issue on GitHub.

---

**Ready to get started?**

```bash
py test_workflow.py  # Verify engine
py test_api.py       # Verify API
py run_server.py     # Start server
```

Then visit: `http://localhost:8000/docs`
